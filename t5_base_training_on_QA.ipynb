{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t5_base_train.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariamDundua/Mariam-Dundua/blob/master/t5_base_training_on_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnz424FisAV"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2V5-o9Whfd0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_V2AkYQSNuX"
      },
      "source": [
        "!pip install grpcio-tools==1.34.1\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1X7iUgjiG4Y"
      },
      "source": [
        "#!pip install --quiet transformers==4.1.1\n",
        "!pip install --quiet pytorch-lightning==1.1.3\n",
        "#!pip install pytorch-lightning\n",
        "!pip install --quiet tokenizers==0.9.4\n",
        "!pip install --quiet sentencepiece==0.1.94"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b156kRZcSbUa"
      },
      "source": [
        "!pip install datasets transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e4kZ8-NlK8W"
      },
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psb3-XrKlww0"
      },
      "source": [
        "!apt install git-lfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsoadj_HDib-"
      },
      "source": [
        "!pip install torchtext==0.8.0 torch==1.7.1 pytorch-lightning==1.1.3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46CGQFsHErhI"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install PyDrive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfCA_1qtQqtP"
      },
      "source": [
        "import transformers\n",
        "\n",
        "print(transformers.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FULrpU5ovfY"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pytorch_lightning as pl\n",
        "#import pytorch_lightning as pl\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored\n",
        "import textwrap\n",
        "from transformers import (AdamW,\n",
        "                          T5ForConditionalGeneration,\n",
        "                          T5Tokenizer,\n",
        "                          get_linear_schedule_with_warmup)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaqwX2zmuBi9"
      },
      "source": [
        "pl.seed_everything(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5esBR5veucUr"
      },
      "source": [
        "Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnk6iy8buaKV"
      },
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "dt=(uploaded['answers.json'])\n",
        "dataa = json.loads(dt)\n",
        "dataa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFblul5-gfE6"
      },
      "source": [
        "import pandas as pd\n",
        "data=pd.DataFrame(columns=['context','question','answers','answer_start','document_id','question_id','is_impossible'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D9h5eJJg7sl"
      },
      "source": [
        "for i in range(120):\n",
        "  for j in range(len(dataa['data'][i]['paragraphs'][0]['qas'])):\n",
        "\n",
        "    data=data.append({'question':dataa['data'][i]['paragraphs'][0]['qas'][j]['question'],\n",
        "                      'is_impossible':dataa['data'][i]['paragraphs'][0]['qas'][j]['is_impossible'],\n",
        "                      'answers':dataa['data'][i]['paragraphs'][0]['qas'][j]['answers'][0]['text'],\n",
        "                      'answer_start':dataa['data'][i]['paragraphs'][0]['qas'][j]['answers'][0]['answer_start'],\n",
        "                      'document_id':dataa['data'][i]['paragraphs'][0]['qas'][j]['answers'][0]['document_id'],\n",
        "                      'id':dataa['data'][i]['paragraphs'][0]['qas'][j]['answers'][0]['question_id'],\n",
        "                      'context':dataa['data'][i]['paragraphs'][0]['context']   \n",
        "                      },ignore_index = True)\n",
        "data['id']=data['id'].astype('object')   \n",
        "data['document_id']=data['document_id'].astype('object')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4EGBgKtjBKD"
      },
      "source": [
        "data['answer_len']=[len(i) for i in data['answers'].tolist()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJJ2_arCiwj2"
      },
      "source": [
        "data['answer_end']=data['answer_start']+data['answer_len']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCPhngiXhCwF"
      },
      "source": [
        "license=[239179,239180,239181,239183,239184,239185]\n",
        "dt=pd.DataFrame(columns=['context','question','answers','answer_start','document_id','question_id','is_impossible','answer_end','answer_len'])\n",
        "for i in license:\n",
        "  dt=dt.append(data[data['document_id']==i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Q1owsZhRmR"
      },
      "source": [
        "data.drop(dt.index,axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i-K8BKQhXP7"
      },
      "source": [
        "def color_answer(qest_ans):\n",
        "  answer_start,answer_end=qest_ans['answer_start'],qest_ans['answer_end']\n",
        "  context=qest_ans['context']\n",
        "  return colored(context[:answer_start],'white')+ colored(context[answer_start:answer_end+1],'blue')+colored(context[answer_end+1:],'white')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEWSOZtHhXUR"
      },
      "source": [
        "from termcolor import colored\n",
        "import textwrap\n",
        "print(\"Question:{}\".format(data.iloc[2].question))\n",
        "print('==================================')\n",
        "print('==================================')\n",
        "print('==================================')\n",
        "print('')\n",
        "#color_answer(data.iloc[0])\n",
        "for wrap in textwrap.wrap(color_answer(data.iloc[2]),width=100):\n",
        "  print(wrap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWLPCvHb22MD"
      },
      "source": [
        "Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJei5ryZ23e_"
      },
      "source": [
        "#model_t5='t5-large'\n",
        "model_t5='t5-base'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_rrabe3MAS"
      },
      "source": [
        "tokenizer=T5Tokenizer.from_pretrained(model_t5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezzD44lPyyf5"
      },
      "source": [
        "class legal_dataset(Dataset):\n",
        "  def __init__(self,\n",
        "               data: pd.DataFrame,\n",
        "               tokenizer:T5Tokenizer,\n",
        "               source_max_token_length: int=1000,\n",
        "               target_max_token_length: int=400):\n",
        "    self.tokenizer=tokenizer\n",
        "    self.data=data\n",
        "    self.source_max_token_length=source_max_token_length\n",
        "    self.target_max_token_length=target_max_token_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)  \n",
        "  def __getitem__(self,index: int):\n",
        "    data_row=self.data.iloc[index]  \n",
        "    source_encoding=tokenizer(\n",
        "      data_row['question'],\n",
        "      data_row['context'],\n",
        "      max_length=self.source_max_token_length,\n",
        "      padding='max_length',\n",
        "      truncation='only_second',\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors='pt')\n",
        "    target_encoding=tokenizer(\n",
        "      data_row['answers'],\n",
        "      max_length=self.target_max_token_length,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors='pt')\n",
        "    \n",
        "    labels=target_encoding['input_ids']\n",
        "    labels[labels==0]=-100\n",
        "    return dict(\n",
        "        question=data_row['question'],\n",
        "        context=data_row['context'],\n",
        "        answer_text=data_row['answers'],\n",
        "        input_ids=source_encoding['input_ids'].flatten(),\n",
        "        attention_mask=source_encoding['attention_mask'].flatten(),\n",
        "        labels=labels.flatten()\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83vIryF5gAiu"
      },
      "source": [
        "class legal_QA_model(pl.LightningDataModule):\n",
        "  def __init__(self,train_df:pd.DataFrame,\n",
        "               test_df:pd.DataFrame,\n",
        "               tokenizer: T5Tokenizer,\n",
        "               batch_size:int=8,\n",
        "               source_max_token_length: int=1000,\n",
        "               target_max_token_length: int=400):\n",
        "    super().__init__()\n",
        "    self.batch_size=batch_size\n",
        "    self.source_max_token_length=source_max_token_length\n",
        "    self.target_max_token_length=target_max_token_length\n",
        "    self.tokenizer=tokenizer\n",
        "    self.train_df=train_df\n",
        "    self.test_df=test_df\n",
        "  def setup(self):\n",
        "    self.train_dataset=legal_dataset(\n",
        "        self.train_df,\n",
        "        self.tokenizer,\n",
        "        self.source_max_token_length,\n",
        "        self.target_max_token_length)\n",
        "    self.test_dataset=legal_dataset(\n",
        "        self.test_df,\n",
        "        self.tokenizer,\n",
        "        self.source_max_token_length,\n",
        "        self.target_max_token_length )\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset,\n",
        "                      batch_size=self.batch_size,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4)\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.test_dataset,\n",
        "                      batch_size=1,\n",
        "                      \n",
        "                      num_workers=4)\n",
        "  def val_dataloader(self):\n",
        "\n",
        "    return DataLoader(self.test_dataset,\n",
        "                      batch_size=1,\n",
        "                      \n",
        "                      num_workers=4)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG4Bhiafjoo3"
      },
      "source": [
        "BATCH_SIZE=1\n",
        "N_EPOCHS=20\n",
        "data_module=legal_QA_model(data,dt,tokenizer,BATCH_SIZE)\n",
        "data_module.setup()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zP0hWX7CXLq"
      },
      "source": [
        "data_module"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pk7iSbpISMb"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RkBNIlRIUqq"
      },
      "source": [
        "class Legal_QA(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model=T5ForConditionalGeneration.from_pretrained(model_t5,return_dict=True)\n",
        "\n",
        "\n",
        "  def forward(self,input_ids, attention_mask,labels=None):\n",
        "    output=self.model(input_ids=input_ids,\n",
        "                 attention_mask=attention_mask,labels=labels)\n",
        "    \n",
        "    return output.loss, output.logits\n",
        "\n",
        "  def training_step(self,batch,batch_idx):\n",
        "    input_ids=batch['input_ids']\n",
        "    attention_mask=batch['attention_mask']\n",
        "    labels=batch['labels']\n",
        "    loss,outputs=self.forward(input_ids, attention_mask,labels)\n",
        "    self.log('train_loss',loss,prog_bar=True,logger=True)\n",
        "    return loss\n",
        "  def validation_step(self,batch,batch_idx):\n",
        "    input_ids=batch['input_ids']\n",
        "    attention_mask=batch['attention_mask']\n",
        "    labels=batch['labels']\n",
        "    loss,outputs=self.forward(input_ids, attention_mask,labels)\n",
        "    self.log('val_loss',loss,prog_bar=True,logger=True)\n",
        "    return loss\n",
        "  def test_step(self,batch,batch_idx):\n",
        "    input_ids=batch['input_ids']\n",
        "    attention_mask=batch['attention_mask']\n",
        "    labels=batch['labels']\n",
        "    loss,outputs=self.forward(input_ids, attention_mask,labels)\n",
        "    self.log('test_loss',loss,prog_bar=True,logger=True)\n",
        "    return loss\n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(),lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-JyIE9DOdkS"
      },
      "source": [
        "my_model=Legal_QA()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWUHME2fOdqN"
      },
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "checkpoint_callback=ModelCheckpoint(\n",
        "    dirpath='checkpoints',\n",
        "    filename='best-checkpoints',\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3aYqW7GQ92A"
      },
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "logger=TensorBoardLogger('training-logs',name='legal-QA')\n",
        "trainer=pl.Trainer(\n",
        "    logger=logger,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    max_epochs=N_EPOCHS,\n",
        "    gpus=1,\n",
        "    progress_bar_refresh_rate=30\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh254YugRZoP"
      },
      "source": [
        "%load_ext tensorboard\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_e_XL9hRo7L"
      },
      "source": [
        "%tensorboard --logdir ./training-logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwYCxCF6iJrc"
      },
      "source": [
        "!rm -rf training_logs\n",
        "!rm -rf lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4vpP6LqR5wW"
      },
      "source": [
        "trainer.fit(my_model,data_module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXNwB05vysMg"
      },
      "source": [
        "trainer.fit(my_model,data_module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAb0dLngyuzT"
      },
      "source": [
        "trainer.test()\n",
        "trained_model=Legal_QA.load_from_checkpoint('checkpoints/best-checkpoints.ckpt')\n",
        "trained_model.freeze()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPvV-wK7y2vm"
      },
      "source": [
        "#save model\n",
        "torch.save(trained_model,'/content/t5modell_n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XRhjZUdi3s7"
      },
      "source": [
        "#Loading trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFRSg5uTHzr1"
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbviD-04H3jB"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh4I6IQBIAFQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSB3bXgHH6Qh"
      },
      "source": [
        "!7z e /content/drive/MyDrive/model_t5.7z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFzJ3I08Ig_2"
      },
      "source": [
        "import torch\n",
        "model_up = torch.load('/content/t5modell')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMsLkJfBEEBJ"
      },
      "source": [
        "def generate_aswer(question,context):\n",
        "  source_encoding=tokenizer(\n",
        "    question,\n",
        "    context,\n",
        "    max_length=1000,\n",
        "    padding='max_length',\n",
        "    truncation='only_second',\n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors='pt')\n",
        "\n",
        "  generated_ids=model_up.model.generate(\n",
        "      \n",
        "      input_ids=source_encoding['input_ids'],\n",
        "      attention_mask=source_encoding['attention_mask'],\n",
        "      num_beams=1,\n",
        "      max_length=400,\n",
        "      repetition_penalty=2.5,\n",
        "      length_penalty=1.0,\n",
        "      early_stopping=True,\n",
        "      use_cache=True)\n",
        "  pred=[tokenizer.decode(generated_id,skip_special_tokens=True,clean_up_tokenization_spaces=True) for generated_id in generated_ids]\n",
        "  return \" \".join(pred)                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msgyiDwRHz6y"
      },
      "source": [
        "ans=[]\n",
        "for i in range(2):  \n",
        "  ans.append(generate_aswer(dt.iloc[0]).question,dt.iloc[0]).context)\n",
        "  print(ans[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqJ5oMKYIzeK"
      },
      "source": [
        "real=[i for i in dt['answers'].tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkkziXl20jCy"
      },
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/t5_base_train.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}